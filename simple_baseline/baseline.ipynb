{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import json\n",
    "import itertools\n",
    "import time \n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import jpeg4py \n",
    "from torchsummary import summary \n",
    "from albumentations.pytorch import ToTensor\n",
    "from albumentations import (Compose, CenterCrop, VerticalFlip, RandomSizedCrop,\n",
    "                            HorizontalFlip, HueSaturationValue, ShiftScaleRotate,\n",
    "                            Resize, RandomCrop, Normalize, Rotate, Normalize)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "print(device)\n",
    "\n",
    "# used constants\n",
    "\n",
    "num_epochs = 10\n",
    "batch_size = 128\n",
    "h, w = 224, 224\n",
    "thresh = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "       BasicConv2d-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "       BasicConv2d-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8          [-1, 192, 56, 56]         110,592\n",
      "       BatchNorm2d-9          [-1, 192, 56, 56]             384\n",
      "      BasicConv2d-10          [-1, 192, 56, 56]               0\n",
      "        MaxPool2d-11          [-1, 192, 28, 28]               0\n",
      "           Conv2d-12           [-1, 64, 28, 28]          12,288\n",
      "      BatchNorm2d-13           [-1, 64, 28, 28]             128\n",
      "      BasicConv2d-14           [-1, 64, 28, 28]               0\n",
      "           Conv2d-15           [-1, 96, 28, 28]          18,432\n",
      "      BatchNorm2d-16           [-1, 96, 28, 28]             192\n",
      "      BasicConv2d-17           [-1, 96, 28, 28]               0\n",
      "           Conv2d-18          [-1, 128, 28, 28]         110,592\n",
      "      BatchNorm2d-19          [-1, 128, 28, 28]             256\n",
      "      BasicConv2d-20          [-1, 128, 28, 28]               0\n",
      "           Conv2d-21           [-1, 16, 28, 28]           3,072\n",
      "      BatchNorm2d-22           [-1, 16, 28, 28]              32\n",
      "      BasicConv2d-23           [-1, 16, 28, 28]               0\n",
      "           Conv2d-24           [-1, 32, 28, 28]           4,608\n",
      "      BatchNorm2d-25           [-1, 32, 28, 28]              64\n",
      "      BasicConv2d-26           [-1, 32, 28, 28]               0\n",
      "        MaxPool2d-27          [-1, 192, 28, 28]               0\n",
      "           Conv2d-28           [-1, 32, 28, 28]           6,144\n",
      "      BatchNorm2d-29           [-1, 32, 28, 28]              64\n",
      "      BasicConv2d-30           [-1, 32, 28, 28]               0\n",
      "        Inception-31          [-1, 256, 28, 28]               0\n",
      "           Conv2d-32          [-1, 128, 28, 28]          32,768\n",
      "      BatchNorm2d-33          [-1, 128, 28, 28]             256\n",
      "      BasicConv2d-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 128, 28, 28]          32,768\n",
      "      BatchNorm2d-36          [-1, 128, 28, 28]             256\n",
      "      BasicConv2d-37          [-1, 128, 28, 28]               0\n",
      "           Conv2d-38          [-1, 192, 28, 28]         221,184\n",
      "      BatchNorm2d-39          [-1, 192, 28, 28]             384\n",
      "      BasicConv2d-40          [-1, 192, 28, 28]               0\n",
      "           Conv2d-41           [-1, 32, 28, 28]           8,192\n",
      "      BatchNorm2d-42           [-1, 32, 28, 28]              64\n",
      "      BasicConv2d-43           [-1, 32, 28, 28]               0\n",
      "           Conv2d-44           [-1, 96, 28, 28]          27,648\n",
      "      BatchNorm2d-45           [-1, 96, 28, 28]             192\n",
      "      BasicConv2d-46           [-1, 96, 28, 28]               0\n",
      "        MaxPool2d-47          [-1, 256, 28, 28]               0\n",
      "           Conv2d-48           [-1, 64, 28, 28]          16,384\n",
      "      BatchNorm2d-49           [-1, 64, 28, 28]             128\n",
      "      BasicConv2d-50           [-1, 64, 28, 28]               0\n",
      "        Inception-51          [-1, 480, 28, 28]               0\n",
      "        MaxPool2d-52          [-1, 480, 14, 14]               0\n",
      "           Conv2d-53          [-1, 192, 14, 14]          92,160\n",
      "      BatchNorm2d-54          [-1, 192, 14, 14]             384\n",
      "      BasicConv2d-55          [-1, 192, 14, 14]               0\n",
      "           Conv2d-56           [-1, 96, 14, 14]          46,080\n",
      "      BatchNorm2d-57           [-1, 96, 14, 14]             192\n",
      "      BasicConv2d-58           [-1, 96, 14, 14]               0\n",
      "           Conv2d-59          [-1, 208, 14, 14]         179,712\n",
      "      BatchNorm2d-60          [-1, 208, 14, 14]             416\n",
      "      BasicConv2d-61          [-1, 208, 14, 14]               0\n",
      "           Conv2d-62           [-1, 16, 14, 14]           7,680\n",
      "      BatchNorm2d-63           [-1, 16, 14, 14]              32\n",
      "      BasicConv2d-64           [-1, 16, 14, 14]               0\n",
      "           Conv2d-65           [-1, 48, 14, 14]           6,912\n",
      "      BatchNorm2d-66           [-1, 48, 14, 14]              96\n",
      "      BasicConv2d-67           [-1, 48, 14, 14]               0\n",
      "        MaxPool2d-68          [-1, 480, 14, 14]               0\n",
      "           Conv2d-69           [-1, 64, 14, 14]          30,720\n",
      "      BatchNorm2d-70           [-1, 64, 14, 14]             128\n",
      "      BasicConv2d-71           [-1, 64, 14, 14]               0\n",
      "        Inception-72          [-1, 512, 14, 14]               0\n",
      "           Conv2d-73          [-1, 160, 14, 14]          81,920\n",
      "      BatchNorm2d-74          [-1, 160, 14, 14]             320\n",
      "      BasicConv2d-75          [-1, 160, 14, 14]               0\n",
      "           Conv2d-76          [-1, 112, 14, 14]          57,344\n",
      "      BatchNorm2d-77          [-1, 112, 14, 14]             224\n",
      "      BasicConv2d-78          [-1, 112, 14, 14]               0\n",
      "           Conv2d-79          [-1, 224, 14, 14]         225,792\n",
      "      BatchNorm2d-80          [-1, 224, 14, 14]             448\n",
      "      BasicConv2d-81          [-1, 224, 14, 14]               0\n",
      "           Conv2d-82           [-1, 24, 14, 14]          12,288\n",
      "      BatchNorm2d-83           [-1, 24, 14, 14]              48\n",
      "      BasicConv2d-84           [-1, 24, 14, 14]               0\n",
      "           Conv2d-85           [-1, 64, 14, 14]          13,824\n",
      "      BatchNorm2d-86           [-1, 64, 14, 14]             128\n",
      "      BasicConv2d-87           [-1, 64, 14, 14]               0\n",
      "        MaxPool2d-88          [-1, 512, 14, 14]               0\n",
      "           Conv2d-89           [-1, 64, 14, 14]          32,768\n",
      "      BatchNorm2d-90           [-1, 64, 14, 14]             128\n",
      "      BasicConv2d-91           [-1, 64, 14, 14]               0\n",
      "        Inception-92          [-1, 512, 14, 14]               0\n",
      "           Conv2d-93          [-1, 128, 14, 14]          65,536\n",
      "      BatchNorm2d-94          [-1, 128, 14, 14]             256\n",
      "      BasicConv2d-95          [-1, 128, 14, 14]               0\n",
      "           Conv2d-96          [-1, 128, 14, 14]          65,536\n",
      "      BatchNorm2d-97          [-1, 128, 14, 14]             256\n",
      "      BasicConv2d-98          [-1, 128, 14, 14]               0\n",
      "           Conv2d-99          [-1, 256, 14, 14]         294,912\n",
      "     BatchNorm2d-100          [-1, 256, 14, 14]             512\n",
      "     BasicConv2d-101          [-1, 256, 14, 14]               0\n",
      "          Conv2d-102           [-1, 24, 14, 14]          12,288\n",
      "     BatchNorm2d-103           [-1, 24, 14, 14]              48\n",
      "     BasicConv2d-104           [-1, 24, 14, 14]               0\n",
      "          Conv2d-105           [-1, 64, 14, 14]          13,824\n",
      "     BatchNorm2d-106           [-1, 64, 14, 14]             128\n",
      "     BasicConv2d-107           [-1, 64, 14, 14]               0\n",
      "       MaxPool2d-108          [-1, 512, 14, 14]               0\n",
      "          Conv2d-109           [-1, 64, 14, 14]          32,768\n",
      "     BatchNorm2d-110           [-1, 64, 14, 14]             128\n",
      "     BasicConv2d-111           [-1, 64, 14, 14]               0\n",
      "       Inception-112          [-1, 512, 14, 14]               0\n",
      "          Conv2d-113          [-1, 112, 14, 14]          57,344\n",
      "     BatchNorm2d-114          [-1, 112, 14, 14]             224\n",
      "     BasicConv2d-115          [-1, 112, 14, 14]               0\n",
      "          Conv2d-116          [-1, 144, 14, 14]          73,728\n",
      "     BatchNorm2d-117          [-1, 144, 14, 14]             288\n",
      "     BasicConv2d-118          [-1, 144, 14, 14]               0\n",
      "          Conv2d-119          [-1, 288, 14, 14]         373,248\n",
      "     BatchNorm2d-120          [-1, 288, 14, 14]             576\n",
      "     BasicConv2d-121          [-1, 288, 14, 14]               0\n",
      "          Conv2d-122           [-1, 32, 14, 14]          16,384\n",
      "     BatchNorm2d-123           [-1, 32, 14, 14]              64\n",
      "     BasicConv2d-124           [-1, 32, 14, 14]               0\n",
      "          Conv2d-125           [-1, 64, 14, 14]          18,432\n",
      "     BatchNorm2d-126           [-1, 64, 14, 14]             128\n",
      "     BasicConv2d-127           [-1, 64, 14, 14]               0\n",
      "       MaxPool2d-128          [-1, 512, 14, 14]               0\n",
      "          Conv2d-129           [-1, 64, 14, 14]          32,768\n",
      "     BatchNorm2d-130           [-1, 64, 14, 14]             128\n",
      "     BasicConv2d-131           [-1, 64, 14, 14]               0\n",
      "       Inception-132          [-1, 528, 14, 14]               0\n",
      "          Conv2d-133          [-1, 256, 14, 14]         135,168\n",
      "     BatchNorm2d-134          [-1, 256, 14, 14]             512\n",
      "     BasicConv2d-135          [-1, 256, 14, 14]               0\n",
      "          Conv2d-136          [-1, 160, 14, 14]          84,480\n",
      "     BatchNorm2d-137          [-1, 160, 14, 14]             320\n",
      "     BasicConv2d-138          [-1, 160, 14, 14]               0\n",
      "          Conv2d-139          [-1, 320, 14, 14]         460,800\n",
      "     BatchNorm2d-140          [-1, 320, 14, 14]             640\n",
      "     BasicConv2d-141          [-1, 320, 14, 14]               0\n",
      "          Conv2d-142           [-1, 32, 14, 14]          16,896\n",
      "     BatchNorm2d-143           [-1, 32, 14, 14]              64\n",
      "     BasicConv2d-144           [-1, 32, 14, 14]               0\n",
      "          Conv2d-145          [-1, 128, 14, 14]          36,864\n",
      "     BatchNorm2d-146          [-1, 128, 14, 14]             256\n",
      "     BasicConv2d-147          [-1, 128, 14, 14]               0\n",
      "       MaxPool2d-148          [-1, 528, 14, 14]               0\n",
      "          Conv2d-149          [-1, 128, 14, 14]          67,584\n",
      "     BatchNorm2d-150          [-1, 128, 14, 14]             256\n",
      "     BasicConv2d-151          [-1, 128, 14, 14]               0\n",
      "       Inception-152          [-1, 832, 14, 14]               0\n",
      "       MaxPool2d-153            [-1, 832, 7, 7]               0\n",
      "          Conv2d-154            [-1, 256, 7, 7]         212,992\n",
      "     BatchNorm2d-155            [-1, 256, 7, 7]             512\n",
      "     BasicConv2d-156            [-1, 256, 7, 7]               0\n",
      "          Conv2d-157            [-1, 160, 7, 7]         133,120\n",
      "     BatchNorm2d-158            [-1, 160, 7, 7]             320\n",
      "     BasicConv2d-159            [-1, 160, 7, 7]               0\n",
      "          Conv2d-160            [-1, 320, 7, 7]         460,800\n",
      "     BatchNorm2d-161            [-1, 320, 7, 7]             640\n",
      "     BasicConv2d-162            [-1, 320, 7, 7]               0\n",
      "          Conv2d-163             [-1, 32, 7, 7]          26,624\n",
      "     BatchNorm2d-164             [-1, 32, 7, 7]              64\n",
      "     BasicConv2d-165             [-1, 32, 7, 7]               0\n",
      "          Conv2d-166            [-1, 128, 7, 7]          36,864\n",
      "     BatchNorm2d-167            [-1, 128, 7, 7]             256\n",
      "     BasicConv2d-168            [-1, 128, 7, 7]               0\n",
      "       MaxPool2d-169            [-1, 832, 7, 7]               0\n",
      "          Conv2d-170            [-1, 128, 7, 7]         106,496\n",
      "     BatchNorm2d-171            [-1, 128, 7, 7]             256\n",
      "     BasicConv2d-172            [-1, 128, 7, 7]               0\n",
      "       Inception-173            [-1, 832, 7, 7]               0\n",
      "          Conv2d-174            [-1, 384, 7, 7]         319,488\n",
      "     BatchNorm2d-175            [-1, 384, 7, 7]             768\n",
      "     BasicConv2d-176            [-1, 384, 7, 7]               0\n",
      "          Conv2d-177            [-1, 192, 7, 7]         159,744\n",
      "     BatchNorm2d-178            [-1, 192, 7, 7]             384\n",
      "     BasicConv2d-179            [-1, 192, 7, 7]               0\n",
      "          Conv2d-180            [-1, 384, 7, 7]         663,552\n",
      "     BatchNorm2d-181            [-1, 384, 7, 7]             768\n",
      "     BasicConv2d-182            [-1, 384, 7, 7]               0\n",
      "          Conv2d-183             [-1, 48, 7, 7]          39,936\n",
      "     BatchNorm2d-184             [-1, 48, 7, 7]              96\n",
      "     BasicConv2d-185             [-1, 48, 7, 7]               0\n",
      "          Conv2d-186            [-1, 128, 7, 7]          55,296\n",
      "     BatchNorm2d-187            [-1, 128, 7, 7]             256\n",
      "     BasicConv2d-188            [-1, 128, 7, 7]               0\n",
      "       MaxPool2d-189            [-1, 832, 7, 7]               0\n",
      "          Conv2d-190            [-1, 128, 7, 7]         106,496\n",
      "     BatchNorm2d-191            [-1, 128, 7, 7]             256\n",
      "     BasicConv2d-192            [-1, 128, 7, 7]               0\n",
      "       Inception-193           [-1, 1024, 7, 7]               0\n",
      "AdaptiveAvgPool2d-194           [-1, 1024, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 5,599,904\n",
      "Trainable params: 5,599,904\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 94.09\n",
      "Params size (MB): 21.36\n",
      "Estimated Total Size (MB): 116.03\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "transforms = {\n",
    "            'train':Compose([\n",
    "        Resize(h, w),\n",
    "        Normalize(),\n",
    "        ToTensor()\n",
    "        ]),\n",
    "            'val':Compose([\n",
    "        Resize(h, w),\n",
    "        Normalize(),\n",
    "        ToTensor()\n",
    "        ]),\n",
    "            'test': Compose([\n",
    "        Resize(h, w),\n",
    "        Normalize(),\n",
    "        ToTensor()\n",
    "        ]),\n",
    "}\n",
    "\n",
    "cnn = models.googlenet(pretrained=True)\n",
    "cnn = nn.Sequential(*list(cnn.children())[:-2])\n",
    "cnn = cnn.to(device)\n",
    "cnn.eval()\n",
    "\n",
    "summary(cnn, (3, h, w))\n",
    "\n",
    "img_embed_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 443757/443757 [00:00<00:00, 2315197.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22531\n"
     ]
    }
   ],
   "source": [
    "# annotations preprocessing\n",
    "\n",
    "with open('VQAv2/train/annotations/v2_mscoco_train2014_annotations.json', 'r') as file:\n",
    "    annotations = json.load(file)\n",
    "\n",
    "ans_list = []\n",
    "\n",
    "for a in tqdm(annotations['annotations']):\n",
    "    ans_list.append(a['multiple_choice_answer'])\n",
    "\n",
    "ans_list = np.unique(ans_list)\n",
    "ans_dict = {v : k for k, v in enumerate(ans_list)}\n",
    "\n",
    "n_ans = len(ans_list)\n",
    "print(n_ans)\n",
    "del ans_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 443757/443757 [00:01<00:00, 422137.75it/s]\n",
      "100%|██████████| 443757/443757 [00:00<00:00, 606148.91it/s]\n",
      "100%|██████████| 443757/443757 [00:00<00:00, 787606.07it/s]\n",
      "100%|██████████| 443757/443757 [00:02<00:00, 159213.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1181\n"
     ]
    }
   ],
   "source": [
    "# questions preprocessing\n",
    "\n",
    "count = {}\n",
    "bag_of_words = {}\n",
    "\n",
    "with open('VQAv2/train/questions/v2_OpenEnded_mscoco_train2014_questions.json', 'r') as file:\n",
    "    questions = json.load(file)\n",
    "    \n",
    "questions = [q['question'].lower()[:-1].split(' ') for q in tqdm(questions['questions'])]\n",
    "\n",
    "for question in tqdm(questions):\n",
    "    for word in question:\n",
    "        if word not in count:\n",
    "            count[word] = 1\n",
    "        else:\n",
    "            count[word] += 1\n",
    "\n",
    "for question in tqdm(questions):\n",
    "    for word in question:\n",
    "        if count[word] > thresh:\n",
    "            if word not in bag_of_words:\n",
    "                bag_of_words[word] = len(bag_of_words) \n",
    "\n",
    "result = []\n",
    "for question in tqdm(questions):\n",
    "    q_vec = np.zeros(len(bag_of_words))\n",
    "    \n",
    "    for word in question:\n",
    "        if word in bag_of_words:\n",
    "            q_vec[bag_of_words[word]] = 1\n",
    "            \n",
    "    result.append(q_vec)\n",
    "\n",
    "questions = np.array(result).astype(bool)\n",
    "\n",
    "q_embed_size = questions.shape[1]\n",
    "print(q_embed_size)\n",
    "del result\n",
    "del bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VQA(Dataset):\n",
    "    def __init__(self, questions, annotations, ans_dict=None,\n",
    "                 images_dir='VQA/train/train2014', transfrom=transforms, train=True): \n",
    "        self.questions = questions\n",
    "        self.annotations = annotations\n",
    "        self.images_dir = images_dir\n",
    "        \n",
    "        if train:\n",
    "            self.train = True\n",
    "            self.ans_dict = ans_dict\n",
    "            self.transform = transforms['train']\n",
    "        else:\n",
    "            self.train = False\n",
    "            self.transform = transforms['val']\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.questions.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        annotation = self.annotations['annotations'][idx]\n",
    "        \n",
    "        image_id = str(annotation['image_id'])\n",
    "        #jpeg = TurboJPEG(r'D:\\Install\\libjpeg-turbo-gcc\\bin\\turbojpeg.dll')\n",
    "        #in_file = open(self.images_dir + \n",
    "        #                     'COCO_train2014_000000' + \n",
    "        #                     image_id.zfill(6) + '.jpg', 'rb')\n",
    "        #image = jpeg.decode(in_file.read())[...,::-1]\n",
    "        #in_file.close()\n",
    "        image = jpeg4py.JPEG(self.images_dir + \n",
    "                             'COCO_train2014_000000' + \n",
    "                             image_id.zfill(6) + '.jpg').decode()\n",
    "        \n",
    "        image = self.transform(image=image)['image']\n",
    "        question = torch.FloatTensor(self.questions[idx])\n",
    "        \n",
    "        if self.train:\n",
    "            answer = self.ans_dict[annotation['multiple_choice_answer']]\n",
    "            return (image, question, answer)\n",
    "        else:\n",
    "            return (image, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = VQA(questions, annotations, ans_dict)\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True, pin_memory = True, num_workers = 8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(1024 + q_embed_size, n_ans)).to(device)\n",
    "\n",
    "error = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 0.002\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, print_every = 100):\n",
    "    model.train() \n",
    "    \n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  \n",
    "    plot_loss_total = 0 \n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "\n",
    "    for i, (imgs, qs, anss) in enumerate(train_loader):\n",
    "        imgs, qs, anss = imgs.to(device), qs.to(device), anss.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        img_embeds = cnn(imgs).reshape((-1, img_embed_size))\n",
    "        txt_embeds = qs\n",
    "        inputs = torch.cat((img_embeds, txt_embeds), 1)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = error(outputs, anss)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += anss.size(0)\n",
    "        correct += (predicted == anss).sum().item()\n",
    "        \n",
    "        print_loss_total += loss.item()\n",
    "        plot_loss_total += loss.item()\n",
    "\n",
    "        if (i + 1) % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            acc = correct / total\n",
    "            correct = 0.0\n",
    "            total = 0.0\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d iters, %d%%) Loss: %.4f Accuracy: %.4f' % (timeSince(start, (i + 1) / len(train_loader)),\n",
    "                                        (i + 1) * batch_size, (i + 1) / len(train_loader) * 100, print_loss_avg, \n",
    "                                        acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 58s (- 33m 2s) (12800 iters, 2%) Loss: 5.9614 Accuracy: 0.1836\n",
      "1m 50s (- 30m 13s) (25600 iters, 5%) Loss: 5.0624 Accuracy: 0.2048\n",
      "2m 41s (- 28m 25s) (38400 iters, 8%) Loss: 4.8341 Accuracy: 0.2244\n",
      "3m 32s (- 27m 11s) (51200 iters, 11%) Loss: 4.7321 Accuracy: 0.2416\n",
      "4m 23s (- 26m 3s) (64000 iters, 14%) Loss: 4.5184 Accuracy: 0.2541\n",
      "5m 14s (- 25m 2s) (76800 iters, 17%) Loss: 4.4664 Accuracy: 0.2640\n",
      "6m 5s (- 24m 3s) (89600 iters, 20%) Loss: 4.4002 Accuracy: 0.2718\n",
      "6m 55s (- 23m 6s) (102400 iters, 23%) Loss: 4.4164 Accuracy: 0.2740\n",
      "7m 46s (- 22m 10s) (115200 iters, 25%) Loss: 4.2029 Accuracy: 0.2870\n",
      "8m 37s (- 21m 16s) (128000 iters, 28%) Loss: 4.1844 Accuracy: 0.2933\n",
      "9m 27s (- 20m 22s) (140800 iters, 31%) Loss: 4.2707 Accuracy: 0.2845\n",
      "10m 20s (- 19m 33s) (153600 iters, 34%) Loss: 4.1617 Accuracy: 0.2882\n",
      "11m 11s (- 18m 39s) (166400 iters, 37%) Loss: 4.1404 Accuracy: 0.2960\n",
      "12m 2s (- 17m 46s) (179200 iters, 40%) Loss: 4.0927 Accuracy: 0.2922\n",
      "12m 53s (- 16m 53s) (192000 iters, 43%) Loss: 4.0249 Accuracy: 0.3005\n",
      "13m 43s (- 16m 1s) (204800 iters, 46%) Loss: 3.9808 Accuracy: 0.3039\n",
      "14m 34s (- 15m 9s) (217600 iters, 49%) Loss: 4.0093 Accuracy: 0.2995\n",
      "15m 25s (- 14m 16s) (230400 iters, 51%) Loss: 3.8726 Accuracy: 0.3114\n",
      "16m 17s (- 13m 25s) (243200 iters, 54%) Loss: 3.9197 Accuracy: 0.3123\n",
      "17m 9s (- 12m 35s) (256000 iters, 57%) Loss: 3.9389 Accuracy: 0.3077\n",
      "18m 0s (- 11m 43s) (268800 iters, 60%) Loss: 3.9465 Accuracy: 0.3108\n",
      "18m 51s (- 10m 51s) (281600 iters, 63%) Loss: 3.8562 Accuracy: 0.3126\n",
      "19m 42s (- 9m 59s) (294400 iters, 66%) Loss: 3.8276 Accuracy: 0.3144\n",
      "20m 33s (- 9m 8s) (307200 iters, 69%) Loss: 3.7995 Accuracy: 0.3216\n",
      "21m 23s (- 8m 16s) (320000 iters, 72%) Loss: 3.8159 Accuracy: 0.3187\n",
      "22m 15s (- 7m 25s) (332800 iters, 74%) Loss: 3.8334 Accuracy: 0.3247\n",
      "23m 8s (- 6m 34s) (345600 iters, 77%) Loss: 3.7117 Accuracy: 0.3216\n",
      "24m 2s (- 5m 43s) (358400 iters, 80%) Loss: 3.7414 Accuracy: 0.3185\n",
      "24m 58s (- 4m 53s) (371200 iters, 83%) Loss: 3.7286 Accuracy: 0.3277\n",
      "25m 51s (- 4m 1s) (384000 iters, 86%) Loss: 3.7553 Accuracy: 0.3303\n",
      "26m 44s (- 3m 9s) (396800 iters, 89%) Loss: 3.7571 Accuracy: 0.3208\n",
      "27m 39s (- 2m 18s) (409600 iters, 92%) Loss: 3.7569 Accuracy: 0.3263\n",
      "28m 32s (- 1m 26s) (422400 iters, 95%) Loss: 3.7661 Accuracy: 0.3291\n",
      "29m 23s (- 0m 34s) (435200 iters, 98%) Loss: 3.6315 Accuracy: 0.3399\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 12] Cannot allocate memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-947284459c22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# evaluate(test_loader)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-f398c059f269>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, print_every)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_SingleProcessDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m             \u001b[0;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/multiprocessing/process.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m                \u001b[0;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpopen_fork\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mSpawnProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m_launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mparent_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 12] Cannot allocate memory"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs): \n",
    "    train(epoch)\n",
    "    lr_scheduler.step()\n",
    "    # evaluate(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
